{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abebu\\DS\\envs\\happy\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm #i like statsmodels result table, lets me explore the coefficents more.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y  X1  X2  X3  X4  X5  X6\n",
       "0  0   3   3   3   4   2   4\n",
       "1  0   3   2   3   5   4   3\n",
       "2  1   5   3   3   3   3   5\n",
       "3  0   5   4   3   3   3   5\n",
       "4  0   5   4   3   3   3   5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load happiness survey data \n",
    "h_customer = pd.read_csv('ACME-HappinessSurvey2020.csv', header=0)\n",
    "h_customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy</th>\n",
       "      <th>order_ontime</th>\n",
       "      <th>order_content_as_expected</th>\n",
       "      <th>ordered_everything</th>\n",
       "      <th>paid_good_price</th>\n",
       "      <th>satisfied_courier</th>\n",
       "      <th>easy_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     happy  order_ontime  order_content_as_expected  ordered_everything  \\\n",
       "0        0             3                          3                   3   \n",
       "1        0             3                          2                   3   \n",
       "2        1             5                          3                   3   \n",
       "3        0             5                          4                   3   \n",
       "4        0             5                          4                   3   \n",
       "..     ...           ...                        ...                 ...   \n",
       "121      1             5                          2                   3   \n",
       "122      1             5                          2                   3   \n",
       "123      1             5                          3                   3   \n",
       "124      0             4                          3                   3   \n",
       "125      0             5                          3                   2   \n",
       "\n",
       "     paid_good_price  satisfied_courier  easy_app  \n",
       "0                  4                  2         4  \n",
       "1                  5                  4         3  \n",
       "2                  3                  3         5  \n",
       "3                  3                  3         5  \n",
       "4                  3                  3         5  \n",
       "..               ...                ...       ...  \n",
       "121                4                  4         3  \n",
       "122                4                  2         5  \n",
       "123                4                  4         5  \n",
       "124                4                  4         5  \n",
       "125                5                  5         5  \n",
       "\n",
       "[126 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets label the columns - helps to know what y or x1, x2 etc are. Alos, this is a managable number of variables. \n",
    "\n",
    "h_customer = h_customer.rename(columns = {'Y': 'happy', 'X1': 'order_ontime', 'X2': 'order_content_as_expected', 'X3': 'ordered_everything', 'X4': 'paid_good_price', 'X5': 'satisfied_courier', 'X6': 'easy_app'})\n",
    "h_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy</th>\n",
       "      <th>order_ontime</th>\n",
       "      <th>order_content_as_expected</th>\n",
       "      <th>ordered_everything</th>\n",
       "      <th>paid_good_price</th>\n",
       "      <th>satisfied_courier</th>\n",
       "      <th>easy_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>126.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.55</td>\n",
       "      <td>4.33</td>\n",
       "      <td>2.53</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.65</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       happy  order_ontime  order_content_as_expected  ordered_everything  \\\n",
       "count 126.00        126.00                     126.00              126.00   \n",
       "mean    0.55          4.33                       2.53                3.31   \n",
       "std     0.50          0.80                       1.11                1.02   \n",
       "min     0.00          1.00                       1.00                1.00   \n",
       "25%     0.00          4.00                       2.00                3.00   \n",
       "50%     1.00          5.00                       3.00                3.00   \n",
       "75%     1.00          5.00                       3.00                4.00   \n",
       "max     1.00          5.00                       5.00                5.00   \n",
       "\n",
       "       paid_good_price  satisfied_courier  easy_app  \n",
       "count           126.00             126.00    126.00  \n",
       "mean              3.75               3.65      4.25  \n",
       "std               0.88               1.15      0.81  \n",
       "min               1.00               1.00      1.00  \n",
       "25%               3.00               3.00      4.00  \n",
       "50%               4.00               4.00      4.00  \n",
       "75%               4.00               4.00      5.00  \n",
       "max               5.00               5.00      5.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It looks like feedback from custmers (features) is on 1-5 scale lets check\n",
    "h_customer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Correlations: Customer Happiness')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets do some visualization to get a sense of the data we have \n",
    "\n",
    "# Compute correlations\n",
    "corr = h_customer.corr()\n",
    "\n",
    "\n",
    "# Set up  matplotlib figure\n",
    "f, ax = plt.subplots(figsize = (12, 12))\n",
    "\n",
    "# Exclude duplicate correlations by masking uper right values\n",
    "mask = np.zeros_like(corr, dtype = np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set background color / chart style\n",
    "sns.set_style(style = 'white')\n",
    "\n",
    "\n",
    "# Add diverging colormap\n",
    "#cmap =sns.diverging_palette(150, 275, s=80, l=55, n=12)\n",
    "cmap = sns.diverging_palette(220, 20, sep = 20, as_cmap = True)\n",
    "\n",
    "# Draw correlation plot\n",
    "sns.heatmap(corr, mask = mask, cmap = cmap, \n",
    "        square = True,\n",
    "        linewidths = .5, cbar_kws = {\"shrink\": .5}, ax = ax)\n",
    "ax.set (title = 'Correlations: Customer Happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy                        0\n",
       "order_ontime                 0\n",
       "order_content_as_expected    0\n",
       "ordered_everything           0\n",
       "paid_good_price              0\n",
       "satisfied_courier            0\n",
       "easy_app                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see if there are any null values \n",
    "h_customer.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 57)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also, we need to check if there are imbalances in the number of happy and unhappy rows.\n",
    "\n",
    "happy, unhappy = h_customer.happy.value_counts()\n",
    "happy, unhappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_ontime</th>\n",
       "      <th>order_content_as_expected</th>\n",
       "      <th>ordered_everything</th>\n",
       "      <th>paid_good_price</th>\n",
       "      <th>satisfied_courier</th>\n",
       "      <th>easy_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     order_ontime  order_content_as_expected  ordered_everything  \\\n",
       "0               3                          3                   3   \n",
       "1               3                          2                   3   \n",
       "2               5                          3                   3   \n",
       "3               5                          4                   3   \n",
       "4               5                          4                   3   \n",
       "..            ...                        ...                 ...   \n",
       "121             5                          2                   3   \n",
       "122             5                          2                   3   \n",
       "123             5                          3                   3   \n",
       "124             4                          3                   3   \n",
       "125             5                          3                   2   \n",
       "\n",
       "     paid_good_price  satisfied_courier  easy_app  \n",
       "0                  4                  2         4  \n",
       "1                  5                  4         3  \n",
       "2                  3                  3         5  \n",
       "3                  3                  3         5  \n",
       "4                  3                  3         5  \n",
       "..               ...                ...       ...  \n",
       "121                4                  4         3  \n",
       "122                4                  2         5  \n",
       "123                4                  4         5  \n",
       "124                4                  4         5  \n",
       "125                5                  5         5  \n",
       "\n",
       "[126 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets separate target variable (y) and the features (x)\n",
    "x = h_customer.drop(['happy'], axis = 1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y, target variable 'happy'\n",
    "\n",
    "y = h_customer['happy'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_ontime_1</th>\n",
       "      <th>order_ontime_3</th>\n",
       "      <th>order_ontime_4</th>\n",
       "      <th>order_ontime_5</th>\n",
       "      <th>order_content_as_expected_1</th>\n",
       "      <th>order_content_as_expected_2</th>\n",
       "      <th>order_content_as_expected_3</th>\n",
       "      <th>order_content_as_expected_4</th>\n",
       "      <th>order_content_as_expected_5</th>\n",
       "      <th>ordered_everything_1</th>\n",
       "      <th>...</th>\n",
       "      <th>satisfied_courier_1</th>\n",
       "      <th>satisfied_courier_2</th>\n",
       "      <th>satisfied_courier_3</th>\n",
       "      <th>satisfied_courier_4</th>\n",
       "      <th>satisfied_courier_5</th>\n",
       "      <th>easy_app_1</th>\n",
       "      <th>easy_app_2</th>\n",
       "      <th>easy_app_3</th>\n",
       "      <th>easy_app_4</th>\n",
       "      <th>easy_app_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     order_ontime_1  order_ontime_3  order_ontime_4  order_ontime_5  \\\n",
       "0                 0               1               0               0   \n",
       "1                 0               1               0               0   \n",
       "2                 0               0               0               1   \n",
       "3                 0               0               0               1   \n",
       "4                 0               0               0               1   \n",
       "..              ...             ...             ...             ...   \n",
       "121               0               0               0               1   \n",
       "122               0               0               0               1   \n",
       "123               0               0               0               1   \n",
       "124               0               0               1               0   \n",
       "125               0               0               0               1   \n",
       "\n",
       "     order_content_as_expected_1  order_content_as_expected_2  \\\n",
       "0                              0                            0   \n",
       "1                              0                            1   \n",
       "2                              0                            0   \n",
       "3                              0                            0   \n",
       "4                              0                            0   \n",
       "..                           ...                          ...   \n",
       "121                            0                            1   \n",
       "122                            0                            1   \n",
       "123                            0                            0   \n",
       "124                            0                            0   \n",
       "125                            0                            0   \n",
       "\n",
       "     order_content_as_expected_3  order_content_as_expected_4  \\\n",
       "0                              1                            0   \n",
       "1                              0                            0   \n",
       "2                              1                            0   \n",
       "3                              0                            1   \n",
       "4                              0                            1   \n",
       "..                           ...                          ...   \n",
       "121                            0                            0   \n",
       "122                            0                            0   \n",
       "123                            1                            0   \n",
       "124                            1                            0   \n",
       "125                            1                            0   \n",
       "\n",
       "     order_content_as_expected_5  ordered_everything_1  ...  \\\n",
       "0                              0                     0  ...   \n",
       "1                              0                     0  ...   \n",
       "2                              0                     0  ...   \n",
       "3                              0                     0  ...   \n",
       "4                              0                     0  ...   \n",
       "..                           ...                   ...  ...   \n",
       "121                            0                     0  ...   \n",
       "122                            0                     0  ...   \n",
       "123                            0                     0  ...   \n",
       "124                            0                     0  ...   \n",
       "125                            0                     0  ...   \n",
       "\n",
       "     satisfied_courier_1  satisfied_courier_2  satisfied_courier_3  \\\n",
       "0                      0                    1                    0   \n",
       "1                      0                    0                    0   \n",
       "2                      0                    0                    1   \n",
       "3                      0                    0                    1   \n",
       "4                      0                    0                    1   \n",
       "..                   ...                  ...                  ...   \n",
       "121                    0                    0                    0   \n",
       "122                    0                    1                    0   \n",
       "123                    0                    0                    0   \n",
       "124                    0                    0                    0   \n",
       "125                    0                    0                    0   \n",
       "\n",
       "     satisfied_courier_4  satisfied_courier_5  easy_app_1  easy_app_2  \\\n",
       "0                      0                    0           0           0   \n",
       "1                      1                    0           0           0   \n",
       "2                      0                    0           0           0   \n",
       "3                      0                    0           0           0   \n",
       "4                      0                    0           0           0   \n",
       "..                   ...                  ...         ...         ...   \n",
       "121                    1                    0           0           0   \n",
       "122                    0                    0           0           0   \n",
       "123                    1                    0           0           0   \n",
       "124                    1                    0           0           0   \n",
       "125                    0                    1           0           0   \n",
       "\n",
       "     easy_app_3  easy_app_4  easy_app_5  \n",
       "0             0           1           0  \n",
       "1             1           0           0  \n",
       "2             0           0           1  \n",
       "3             0           0           1  \n",
       "4             0           0           1  \n",
       "..          ...         ...         ...  \n",
       "121           1           0           0  \n",
       "122           0           0           1  \n",
       "123           0           0           1  \n",
       "124           0           0           1  \n",
       "125           0           0           1  \n",
       "\n",
       "[126 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets change all the features to binary class using get_dummies\n",
    "\n",
    "x = x.astype('category')\n",
    "x = pd.get_dummies(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Nov 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.158</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:32:39</td>     <th>  Log-Likelihood:    </th> <td> -74.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   126</td>      <th>  AIC:               </th> <td>   196.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   102</td>      <th>  BIC:               </th> <td>   264.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    23</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>order_ontime_1</th>              <td>   -0.4624</td> <td>    0.509</td> <td>   -0.909</td> <td> 0.365</td> <td>   -1.471</td> <td>    0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>order_ontime_3</th>              <td>    0.1943</td> <td>    0.148</td> <td>    1.313</td> <td> 0.192</td> <td>   -0.099</td> <td>    0.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>order_ontime_4</th>              <td>    0.0170</td> <td>    0.152</td> <td>    0.112</td> <td> 0.911</td> <td>   -0.285</td> <td>    0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>order_ontime_5</th>              <td>    0.4376</td> <td>    0.155</td> <td>    2.830</td> <td> 0.006</td> <td>    0.131</td> <td>    0.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>order_content_as_expected_1</th> <td>    0.0730</td> <td>    0.106</td> <td>    0.687</td> <td> 0.494</td> <td>   -0.138</td> <td>    0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>order_content_as_expected_2</th> <td>    0.0916</td> <td>    0.103</td> <td>    0.887</td> <td> 0.377</td> <td>   -0.113</td> <td>    0.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>order_content_as_expected_3</th> <td>    0.0441</td> <td>    0.099</td> <td>    0.447</td> <td> 0.656</td> <td>   -0.151</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>order_content_as_expected_4</th> <td>   -0.1246</td> <td>    0.125</td> <td>   -0.999</td> <td> 0.320</td> <td>   -0.372</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>order_content_as_expected_5</th> <td>    0.1024</td> <td>    0.209</td> <td>    0.490</td> <td> 0.625</td> <td>   -0.312</td> <td>    0.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ordered_everything_1</th>        <td>   -0.0536</td> <td>    0.193</td> <td>   -0.278</td> <td> 0.782</td> <td>   -0.436</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ordered_everything_2</th>        <td>   -0.0332</td> <td>    0.139</td> <td>   -0.239</td> <td> 0.812</td> <td>   -0.309</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ordered_everything_3</th>        <td>    0.0393</td> <td>    0.092</td> <td>    0.425</td> <td> 0.672</td> <td>   -0.144</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ordered_everything_4</th>        <td>    0.2159</td> <td>    0.116</td> <td>    1.858</td> <td> 0.066</td> <td>   -0.015</td> <td>    0.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ordered_everything_5</th>        <td>    0.0179</td> <td>    0.164</td> <td>    0.109</td> <td> 0.913</td> <td>   -0.308</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>paid_good_price_1</th>           <td>    0.4141</td> <td>    0.482</td> <td>    0.860</td> <td> 0.392</td> <td>   -0.541</td> <td>    1.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>paid_good_price_2</th>           <td>   -0.3321</td> <td>    0.234</td> <td>   -1.422</td> <td> 0.158</td> <td>   -0.795</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>paid_good_price_3</th>           <td>   -0.0135</td> <td>    0.152</td> <td>   -0.089</td> <td> 0.929</td> <td>   -0.315</td> <td>    0.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>paid_good_price_4</th>           <td>    0.0736</td> <td>    0.146</td> <td>    0.505</td> <td> 0.615</td> <td>   -0.215</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>paid_good_price_5</th>           <td>    0.0444</td> <td>    0.159</td> <td>    0.279</td> <td> 0.781</td> <td>   -0.271</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>satisfied_courier_1</th>         <td>    0.1397</td> <td>    0.231</td> <td>    0.604</td> <td> 0.547</td> <td>   -0.319</td> <td>    0.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>satisfied_courier_2</th>         <td>   -0.0666</td> <td>    0.142</td> <td>   -0.470</td> <td> 0.639</td> <td>   -0.348</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>satisfied_courier_3</th>         <td>    0.0403</td> <td>    0.136</td> <td>    0.296</td> <td> 0.768</td> <td>   -0.229</td> <td>    0.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>satisfied_courier_4</th>         <td>   -0.0485</td> <td>    0.114</td> <td>   -0.424</td> <td> 0.672</td> <td>   -0.275</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>satisfied_courier_5</th>         <td>    0.1215</td> <td>    0.127</td> <td>    0.955</td> <td> 0.342</td> <td>   -0.131</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>easy_app_1</th>                  <td>   -0.0220</td> <td>    0.729</td> <td>   -0.030</td> <td> 0.976</td> <td>   -1.468</td> <td>    1.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>easy_app_2</th>                  <td>   -0.1142</td> <td>    0.574</td> <td>   -0.199</td> <td> 0.843</td> <td>   -1.253</td> <td>    1.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>easy_app_3</th>                  <td>   -0.0386</td> <td>    0.209</td> <td>   -0.184</td> <td> 0.854</td> <td>   -0.454</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>easy_app_4</th>                  <td>    0.3169</td> <td>    0.185</td> <td>    1.712</td> <td> 0.090</td> <td>   -0.050</td> <td>    0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>easy_app_5</th>                  <td>    0.0443</td> <td>    0.185</td> <td>    0.239</td> <td> 0.811</td> <td>   -0.323</td> <td>    0.412</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>43.717</td> <th>  Durbin-Watson:     </th> <td>   1.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>   9.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.317</td> <th>  Prob(JB):          </th> <td> 0.00942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.827</td> <th>  Cond. No.          </th> <td>1.32e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.43e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.233\n",
       "Model:                            OLS   Adj. R-squared:                  0.060\n",
       "Method:                 Least Squares   F-statistic:                     1.347\n",
       "Date:                Tue, 03 Nov 2020   Prob (F-statistic):              0.158\n",
       "Time:                        17:32:39   Log-Likelihood:                -74.167\n",
       "No. Observations:                 126   AIC:                             196.3\n",
       "Df Residuals:                     102   BIC:                             264.4\n",
       "Df Model:                          23                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "order_ontime_1                 -0.4624      0.509     -0.909      0.365      -1.471       0.546\n",
       "order_ontime_3                  0.1943      0.148      1.313      0.192      -0.099       0.488\n",
       "order_ontime_4                  0.0170      0.152      0.112      0.911      -0.285       0.319\n",
       "order_ontime_5                  0.4376      0.155      2.830      0.006       0.131       0.744\n",
       "order_content_as_expected_1     0.0730      0.106      0.687      0.494      -0.138       0.284\n",
       "order_content_as_expected_2     0.0916      0.103      0.887      0.377      -0.113       0.296\n",
       "order_content_as_expected_3     0.0441      0.099      0.447      0.656      -0.151       0.240\n",
       "order_content_as_expected_4    -0.1246      0.125     -0.999      0.320      -0.372       0.123\n",
       "order_content_as_expected_5     0.1024      0.209      0.490      0.625      -0.312       0.517\n",
       "ordered_everything_1           -0.0536      0.193     -0.278      0.782      -0.436       0.329\n",
       "ordered_everything_2           -0.0332      0.139     -0.239      0.812      -0.309       0.243\n",
       "ordered_everything_3            0.0393      0.092      0.425      0.672      -0.144       0.223\n",
       "ordered_everything_4            0.2159      0.116      1.858      0.066      -0.015       0.446\n",
       "ordered_everything_5            0.0179      0.164      0.109      0.913      -0.308       0.344\n",
       "paid_good_price_1               0.4141      0.482      0.860      0.392      -0.541       1.369\n",
       "paid_good_price_2              -0.3321      0.234     -1.422      0.158      -0.795       0.131\n",
       "paid_good_price_3              -0.0135      0.152     -0.089      0.929      -0.315       0.288\n",
       "paid_good_price_4               0.0736      0.146      0.505      0.615      -0.215       0.362\n",
       "paid_good_price_5               0.0444      0.159      0.279      0.781      -0.271       0.359\n",
       "satisfied_courier_1             0.1397      0.231      0.604      0.547      -0.319       0.598\n",
       "satisfied_courier_2            -0.0666      0.142     -0.470      0.639      -0.348       0.214\n",
       "satisfied_courier_3             0.0403      0.136      0.296      0.768      -0.229       0.310\n",
       "satisfied_courier_4            -0.0485      0.114     -0.424      0.672      -0.275       0.178\n",
       "satisfied_courier_5             0.1215      0.127      0.955      0.342      -0.131       0.374\n",
       "easy_app_1                     -0.0220      0.729     -0.030      0.976      -1.468       1.424\n",
       "easy_app_2                     -0.1142      0.574     -0.199      0.843      -1.253       1.024\n",
       "easy_app_3                     -0.0386      0.209     -0.184      0.854      -0.454       0.377\n",
       "easy_app_4                      0.3169      0.185      1.712      0.090      -0.050       0.684\n",
       "easy_app_5                      0.0443      0.185      0.239      0.811      -0.323       0.412\n",
       "==============================================================================\n",
       "Omnibus:                       43.717   Durbin-Watson:                   1.906\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                9.330\n",
       "Skew:                          -0.317   Prob(JB):                      0.00942\n",
       "Kurtosis:                       1.827   Cond. No.                     1.32e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.43e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statsmodel.api output has a more interpretable OLS regression table  \n",
    "\n",
    "OLS_reg = sm.OLS(y,x)\n",
    "result = OLS_reg.fit()\n",
    "result.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it looks like delivering orders ontime (ordering everything a customer wanted, and having an app that makes it easy to order seems to be the most significant predicting features). An interesting observation is that sometimes we find _4 to be signficant than _5, this can only be due to small sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 668.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Accuracy  Balanced Accuracy  ROC AUC  F1 Score  Time Taken\n",
      "Model                                                                         \n",
      "DummyClassifier         0.54               0.57     0.57      0.54        0.00\n",
      "CheckingClassifier      0.62               0.50     0.50      0.47        0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Explore which models would work well with this dataset. `lazyPredict` helps generate sutable models. \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 123)\n",
    "\n",
    "clf = LazyClassifier(verbose = 0, ignore_warnings = True, predictions = True, custom_metric = None)\n",
    "models,predictions = clf.fit(x_train, x_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Classifier</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             train_accuracy test_accuracy\n",
       "Random Forest Classifier               0.95          0.58\n",
       "Gradient Boosting Classifier           0.95          0.58\n",
       "Logistic Regression                    0.72          0.54\n",
       "SVC                                    0.70          0.50\n",
       "Ridge Classifier                       0.72          0.54\n",
       "AdaBoost Classifier                    0.72          0.58\n",
       "KNeighborsClassifier                   0.78          0.50\n",
       "Bagging Classifier                     0.95          0.58\n",
       "Bernoulli Naive Bayes                  0.69          0.58\n",
       "MLP Classifier                         0.95          0.65"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Well the 'lazyPredict' did not work, despite creating a separate vertual environment for the project. I am going to implement select models that I think may perfrom well for such dataset and business problem, manually. \n",
    "\n",
    "def evaluate(x_train, x_test, y_train, y_test):\n",
    "    #Names of models\n",
    "    model_name_list = ['Random Forest Classifier',\n",
    "                       'Gradient Boosting Classifier', \n",
    "                      'Logistic Regression',\n",
    "                      'SVC',\n",
    "                      'Ridge Classifier',\n",
    "                      'AdaBoost Classifier',\n",
    "                      'KNeighborsClassifier',\n",
    "                      'Bagging Classifier',\n",
    "                      'Bernoulli Naive Bayes',\n",
    "                      'MLP Classifier']\n",
    "    model = np.arange(1, 11)\n",
    "    train_accuracy = np.empty(len(model))\n",
    "    test_accuracy = np.empty(len(model))\n",
    "    # Instantiate the models\n",
    "    model1 = RandomForestClassifier(n_estimators=100)\n",
    "    model2 = GradientBoostingClassifier(n_estimators=100)\n",
    "    model3 = LogisticRegression()\n",
    "    model4 = SVC (gamma='auto')\n",
    "    model5 = RidgeClassifier ()\n",
    "    model6 = AdaBoostClassifier (n_estimators=100)\n",
    "    model7 = KNeighborsClassifier (n_neighbors=3)\n",
    "    model8 = BaggingClassifier(n_estimators=100)\n",
    "    model9 = BernoulliNB()\n",
    "    model10 = MLPClassifier (max_iter=300)\n",
    "    results =pd.DataFrame(columns=['train_accuracy', 'test_accuracy'])    \n",
    "    \n",
    "    model_list = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10]\n",
    "    # Train and predict with each model\n",
    "    for i, model in enumerate(model_list):\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        train_accuracy=model.score(x_train, y_train)\n",
    "        test_accuracy=model.score(x_test, y_test)\n",
    "        \n",
    "        model_name=model_name_list[i]\n",
    "        results.loc[model_name, :] =[train_accuracy, test_accuracy]\n",
    "    return results\n",
    "\n",
    "\n",
    "results = evaluate(x_train, x_test, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensamble (random forest, gradient boosting, and bagging) and the neurarl network model (MLP), fitted very well on the training data (each with 95% accuracy). However, all the models have overfitted and are biased towards the training data. One solution is using cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_train_cv_accuracy</th>\n",
       "      <th>avg_test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Classifier</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             avg_train_cv_accuracy avg_test_accuracy\n",
       "Random Forest Classifier                      0.61              0.50\n",
       "Gradient Boosting Classifier                  0.58              0.42\n",
       "Logistic Regression                           0.60              0.50\n",
       "SVC                                           0.59              0.61\n",
       "Ridge Classifier                              0.59              0.50\n",
       "AdaBoost Classifier                           0.57              0.66\n",
       "KNeighborsClassifier                          0.56              0.57\n",
       "Bagging Classifier                            0.61              0.30\n",
       "Bernoulli Naive Bayes                         0.61              0.39\n",
       "MLP Classifier                                0.61              0.67"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cv_evaluate(x_train, x_test, y_train, y_test):\n",
    "    #Names of models\n",
    "    model_name_list = ['Random Forest Classifier',\n",
    "                       'Gradient Boosting Classifier', \n",
    "                      'Logistic Regression',\n",
    "                      'SVC',\n",
    "                      'Ridge Classifier',\n",
    "                      'AdaBoost Classifier',\n",
    "                      'KNeighborsClassifier',\n",
    "                      'Bagging Classifier',\n",
    "                      'Bernoulli Naive Bayes',\n",
    "                      'MLP Classifier']\n",
    "    model = np.arange(1, 11)\n",
    "    avg_train_cv_accuracy = np.empty(len(model))\n",
    "    test_accuracy = np.empty(len(model))\n",
    "    # Instantiate the models\n",
    "    model1 = RandomForestClassifier(n_estimators=100)\n",
    "    model2 = GradientBoostingClassifier(n_estimators=100)\n",
    "    model3 = LogisticRegression()\n",
    "    model4 = SVC (gamma='auto')\n",
    "    model5 = RidgeClassifier ()\n",
    "    model6 = AdaBoostClassifier (n_estimators=100)\n",
    "    model7 = KNeighborsClassifier (n_neighbors=3)\n",
    "    model8 = BaggingClassifier(n_estimators=100)\n",
    "    model9 = BernoulliNB()\n",
    "    model10 = MLPClassifier (max_iter=300)\n",
    "    results =pd.DataFrame(columns=['avg_train_cv_accuracy', 'avg_test_accuracy'])    \n",
    "    \n",
    "    model_list = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10]\n",
    "    # Train and predict with each model\n",
    "    for i, model in enumerate(model_list):\n",
    "        model.fit(x_train, y_train)\n",
    "              \n",
    "        train_cv_accuracy = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 5)\n",
    "        avg_train_cv_accuracy = train_cv_accuracy.mean()\n",
    "        test_cv_accuracy = cross_val_score(estimator = model, X = x_test, y = y_test, cv = 5)\n",
    "        avg_test_cv_accuracy = test_cv_accuracy.mean()\n",
    "        \n",
    "        model_name=model_name_list[i]\n",
    "        results.loc[model_name, :] = [avg_train_cv_accuracy, avg_test_cv_accuracy]\n",
    "    return results\n",
    "\n",
    "\n",
    "results = cv_evaluate(x_train, x_test, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, although the model performance reduced significantly, the variance between training data and testing data performance is low. Random forest and gradient boosting cassifiers have performed better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_train_cv_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Classifier</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             avg_train_cv_accuracy test_accuracy\n",
       "Random Forest Classifier                      0.58          0.58\n",
       "Gradient Boosting Classifier                  0.58          0.62\n",
       "Logistic Regression                           0.60          0.54\n",
       "SVC                                           0.59          0.50\n",
       "Ridge Classifier                              0.59          0.54\n",
       "AdaBoost Classifier                           0.57          0.58\n",
       "KNeighborsClassifier                          0.56          0.50\n",
       "Bagging Classifier                            0.59          0.62\n",
       "Bernoulli Naive Bayes                         0.61          0.58\n",
       "MLP Classifier                                0.59          0.58"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considering this is a small dataset spliting further may be the problem on model performance. Lets see what happens if we use CV resample method on the entire dataset. \n",
    "\n",
    "def cv_evaluate(x_train, x_test, y_train, y_test):\n",
    "    #Names of models\n",
    "    model_name_list = ['Random Forest Classifier',\n",
    "                       'Gradient Boosting Classifier', \n",
    "                      'Logistic Regression',\n",
    "                      'SVC',\n",
    "                      'Ridge Classifier',\n",
    "                      'AdaBoost Classifier',\n",
    "                      'KNeighborsClassifier',\n",
    "                      'Bagging Classifier',\n",
    "                      'Bernoulli Naive Bayes',\n",
    "                      'MLP Classifier']\n",
    "    model = np.arange(1, 11)\n",
    "    avg_train_cv_accuracy = np.empty(len(model))\n",
    "    test_accuracy = np.empty(len(model))\n",
    "    # Instantiate the models\n",
    "    model1 = RandomForestClassifier(n_estimators=100)\n",
    "    model2 = GradientBoostingClassifier(n_estimators=100)\n",
    "    model3 = LogisticRegression()\n",
    "    model4 = SVC (gamma='auto')\n",
    "    model5 = RidgeClassifier ()\n",
    "    model6 = AdaBoostClassifier (n_estimators=100)\n",
    "    model7 = KNeighborsClassifier (n_neighbors=3)\n",
    "    model8 = BaggingClassifier(n_estimators=100)\n",
    "    model9 = BernoulliNB()\n",
    "    model10 = MLPClassifier (max_iter=300)\n",
    "    results =pd.DataFrame(columns=['avg_train_cv_accuracy', 'test_accuracy'])    \n",
    "    \n",
    "    model_list = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10]\n",
    "    # Train and predict with each model\n",
    "    for i, model in enumerate(model_list):\n",
    "        model.fit(x_train, y_train)\n",
    "              \n",
    "        train_cv_accuracy = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 5)\n",
    "        avg_train_cv_accuracy = train_cv_accuracy.mean()\n",
    "        test_accuracy = model.score(x_test, y_test)\n",
    "        \n",
    "        model_name=model_name_list[i]\n",
    "        results.loc[model_name, :] = [avg_train_cv_accuracy, test_accuracy]\n",
    "    return results\n",
    "\n",
    "\n",
    "results = cv_evaluate(x_train, x_test, y_train, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_accuracies</th>\n",
       "      <th>avg_cv_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>[0.65, 0.44, 0.52, 0.8, 0.52]</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>[0.5, 0.48, 0.68, 0.76, 0.52]</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>[0.62, 0.52, 0.6, 0.68, 0.56]</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>[0.58, 0.48, 0.6, 0.64, 0.56]</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Classifier</th>\n",
       "      <td>[0.58, 0.52, 0.6, 0.68, 0.6]</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>[0.54, 0.48, 0.4, 0.68, 0.52]</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>[0.42, 0.64, 0.64, 0.64, 0.56]</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>[0.62, 0.48, 0.56, 0.72, 0.64]</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli Naive Bayes</th>\n",
       "      <td>[0.54, 0.6, 0.64, 0.8, 0.48]</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Classifier</th>\n",
       "      <td>[0.62, 0.4, 0.6, 0.72, 0.48]</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               cv_accuracies avg_cv_accuracy\n",
       "Random Forest Classifier       [0.65, 0.44, 0.52, 0.8, 0.52]            0.59\n",
       "Gradient Boosting Classifier   [0.5, 0.48, 0.68, 0.76, 0.52]            0.59\n",
       "Logistic Regression            [0.62, 0.52, 0.6, 0.68, 0.56]            0.60\n",
       "SVC                            [0.58, 0.48, 0.6, 0.64, 0.56]            0.57\n",
       "Ridge Classifier                [0.58, 0.52, 0.6, 0.68, 0.6]            0.60\n",
       "AdaBoost Classifier            [0.54, 0.48, 0.4, 0.68, 0.52]            0.52\n",
       "KNeighborsClassifier          [0.42, 0.64, 0.64, 0.64, 0.56]            0.58\n",
       "Bagging Classifier            [0.62, 0.48, 0.56, 0.72, 0.64]            0.60\n",
       "Bernoulli Naive Bayes           [0.54, 0.6, 0.64, 0.8, 0.48]            0.61\n",
       "MLP Classifier                  [0.62, 0.4, 0.6, 0.72, 0.48]            0.56"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cv_evaluate(x, y):\n",
    "    #Names of models\n",
    "    model_name_list = ['Random Forest Classifier',\n",
    "                       'Gradient Boosting Classifier', \n",
    "                      'Logistic Regression',\n",
    "                      'SVC',\n",
    "                      'Ridge Classifier',\n",
    "                      'AdaBoost Classifier',\n",
    "                      'KNeighborsClassifier',\n",
    "                      'Bagging Classifier',\n",
    "                      'Bernoulli Naive Bayes',\n",
    "                      'MLP Classifier']\n",
    "    model = np.arange(1, 11)\n",
    "    cv_accuracies = np.empty(len(model))\n",
    "    avg_cv_accuracy = np.empty(len(model))\n",
    "    # Instantiate the models\n",
    "    model1 = RandomForestClassifier(n_estimators=100)\n",
    "    model2 = GradientBoostingClassifier(n_estimators=100)\n",
    "    model3 = LogisticRegression()\n",
    "    model4 = SVC (gamma='auto')\n",
    "    model5 = RidgeClassifier ()\n",
    "    model6 = AdaBoostClassifier (n_estimators=100)\n",
    "    model7 = KNeighborsClassifier (n_neighbors=3)\n",
    "    model8 = BaggingClassifier(n_estimators=100)\n",
    "    model9 = BernoulliNB()\n",
    "    model10 = MLPClassifier (max_iter=300)\n",
    "    results =pd.DataFrame(columns=['cv_accuracies', 'avg_cv_accuracy'])    \n",
    "    \n",
    "    model_list = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10]\n",
    "    # Train and predict with each model\n",
    "    for i, model in enumerate(model_list):\n",
    "        model.fit(x, y)\n",
    "              \n",
    "        cv_accuracies = cross_val_score(estimator = model, X = x, y = y, cv = 5)\n",
    "        avg_cv_accuracy = cv_accuracies.mean()\n",
    "        \n",
    "        model_name=model_name_list[i]\n",
    "        results.loc[model_name, :] = [np.round(cv_accuracies, 2), avg_cv_accuracy]\n",
    "    return results\n",
    "\n",
    "\n",
    "results = cv_evaluate(x, y)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spliting the small dataset wasn't the issue here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on training data: 0.6399999999999999 using {'bootstrap': True, 'max_depth': 80, 'max_features': 2, 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Lets pick the top 2 models and finetune the parameters by combining grid search with CV resampling method to further imporve model accuracy. \n",
    "# The top 2 best performing models are `RandomForestClassifier` and `MLPClassifier`.\n",
    "\n",
    "model1 = RandomForestClassifier()\n",
    "\n",
    "# define parameter values\n",
    " \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "# define grid search\n",
    "grid_search = GridSearchCV(estimator = model1, param_grid = param_grid, n_jobs = -1, cv = 5, scoring = 'accuracy', error_score = 0, verbose = 2)\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(f\"Best score on training data: {grid_result.best_score_} using {grid_result.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy on testing data: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "# Best score on testing data\n",
    "rfc = RandomForestClassifier(bootstrap =  True, max_depth = 80, max_features = 2, min_samples_leaf = 4, min_samples_split = 8, n_estimators = 200)\n",
    "rfc.fit(x_test, y_test)\n",
    "\n",
    "test_accuracy = rfc.score(x_test, y_test)\n",
    "\n",
    "# summarize results\n",
    "print(f\"Random Forest Classifier Accuracy on testing data: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on training data: 0.6599999999999999 using {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "model10 = MLPClassifier (max_iter=100)\n",
    "\n",
    "# define parameter values\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "# define grid search\n",
    "grid_search = GridSearchCV(estimator = model10, param_grid = parameter_space, n_jobs = -1, cv = 5, scoring = 'accuracy', error_score = 0)\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(f\"Best score on training data: {grid_result.best_score_} using {grid_result.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy on testing data: 0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "# Best score on testing data\n",
    "mlp = MLPClassifier (hidden_layer_sizes = (100,), activation = 'relu', solver = 'adam', alpha = 0.0001, learning_rate = 'adaptive')\n",
    "mlp.fit(x_test, y_test)\n",
    "\n",
    "test_accuracy = mlp.score(x_test, y_test)\n",
    "\n",
    "# summarize results\n",
    "print(f\"Random Forest Classifier Accuracy on testing data: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
